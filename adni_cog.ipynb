{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_tar)\n",
    "\n",
    "adj = np.loadtxt('../cogd/model/graph/mci_connectome.csv',delimiter=',')\n",
    "a = coo_matrix(adj)\n",
    "\n",
    "class ASet(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        super(ASet, self).__init__(root, transform)\n",
    "        path = self.processed_paths[0] if train else self.processed_paths[1]\n",
    "        self.data, self.slices = torch.load(path)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train1.csv', 'test1.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['training.pt', 'test.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "        #print('no download avail..')\n",
    "\n",
    "    def process(self):\n",
    "        #connectome\n",
    "        adj = np.loadtxt('../cogd/model/graph/mci_connectome.csv',delimiter=',')\n",
    "        a = coo_matrix(adj)\n",
    "\n",
    "        #load\n",
    "        train_path = \"../cogd/model/data/imaging/kfold/train1.csv\"\n",
    "        test_path  = \"../cogd/model/data/imaging/kfold/test1.csv\"\n",
    "        train = np.loadtxt(train_path,delimiter=',',skiprows=1)\n",
    "        test = np.loadtxt(test_path,delimiter=',',skiprows=1)\n",
    "        data_list = []\n",
    "        \n",
    "        for m in train:\n",
    "            edge_index = torch.tensor([a.row,a.col], dtype=torch.long) # [2, num_edges] coo format\n",
    "            edge_attr  = torch.tensor(np.transpose([a.data]), dtype=torch.float) # [num_edges, num_edge_features]\n",
    "            node_feat = np.reshape(m[2:], (86,2), order='F')\n",
    "            x = torch.tensor(node_feat, dtype=torch.float) # [num_nodes, num_node_features]\n",
    "            y = torch.tensor([m[0]-1], dtype=torch.long)\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = ASet(root='./data/adni/')\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "loader = DataLoader(data, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([258, 2])\n",
      "conv1 -> torch.Size([258, 5])\n",
      "conv2 -> torch.Size([258, 10])\n",
      "dense-relu -> torch.Size([258, 112])\n",
      "torch.Size([258, 112])\n",
      "torch.Size([258, 112]) torch.Size([3])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "binary_cross_entropy_with_logits() got an unexpected keyword argument 'reduction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fdc23c8bc9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#sum of the output will be divided by the number of elements in the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m#         loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#         optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binary_cross_entropy_with_logits() got an unexpected keyword argument 'reduction'"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = ChebConv(data.num_features, 5, 4)\n",
    "        self.conv2 = ChebConv(5, 10, 2)\n",
    "        self.dense = Linear(10, 112)\n",
    "        self.dense2 = Linear(112, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        print('input:',x.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        print('conv1 ->', x.shape)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        print('conv2 ->', x.shape)\n",
    "        x = F.relu(self.dense(x))\n",
    "        print('dense-relu ->', x.shape)\n",
    "        #x = torch.sum(x, dim=0)\n",
    "        print(x.shape)\n",
    "\n",
    "        # goal is to return [batch_size, data.num_features]\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(out.shape, data.y.shape)\n",
    "        #sum of the output will be divided by the number of elements in the output\n",
    "        loss = F.binary_cross_entropy_with_logits(out, data.y, reduction='elementwise_mean')\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
